#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒè®­ç»ƒæ¨¡å— - åŸºäºMS-Swiftçš„å¾®è°ƒè®­ç»ƒå™¨
æ”¯æŒLoRAã€QLoRAã€å…¨å‚æ•°å¾®è°ƒã€å¤šæ¨¡æ€å¾®è°ƒ
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Union

# æ·»åŠ utilsè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent / "1_utils"))

from config_loader import ConfigLoader
from logger import Logger

try:
    from swift.llm import sft_main
    from swift.utils import get_logger as swift_get_logger
except ImportError as e:
    print(f"âŒ å¯¼å…¥Swiftæ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…ms-swift: pip install ms-swift")
    sys.exit(1)

import torch

class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨ - ç»Ÿä¸€çš„å¾®è°ƒè®­ç»ƒæ¥å£"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è®­ç»ƒç®¡ç†å™¨
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.logger = Logger("TrainingManager").get_logger()
        self.config_loader = ConfigLoader()
        
        # åŠ è½½é…ç½®
        if config_path:
            self.config = self.config_loader.load_config(config_path)
        else:
            self.config = {}
            
        self.swift_logger = swift_get_logger()
        self.setup_environment()
    
    def setup_environment(self):
        """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            self.logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {device_count} å¼ GPU")
            for i in range(device_count):
                gpu_name = torch.cuda.get_device_name(i)
                memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                self.logger.info(f"  GPU {i}: {gpu_name} ({memory:.1f}GB)")
        else:
            self.logger.warning("âš ï¸  æœªæ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆä¸æ¨èï¼‰")
    
    def prepare_training_args(self, train_config: Dict[str, Any]) -> List[str]:
        """
        å‡†å¤‡è®­ç»ƒå‚æ•°
        Args:
            train_config: è®­ç»ƒé…ç½®å­—å…¸
        Returns:
            List[str]: å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨
        """
        model = train_config.get('model', 'Qwen/Qwen2.5-7B-Instruct')
        dataset = train_config.get('dataset', ['AI-ModelScope/alpaca-gpt4-data-zh#1000'])
        output_dir = train_config.get('output_dir', './output')
        train_type = train_config.get('train_type', 'lora')
        
        # åŸºç¡€å‚æ•°
        args = [
            '--model', model,
            '--dataset', ' '.join(dataset if isinstance(dataset, list) else [dataset]),
            '--train_type', train_type,
            '--output_dir', output_dir,
            '--num_train_epochs', str(train_config.get('num_train_epochs', 3)),
            '--per_device_train_batch_size', str(train_config.get('per_device_train_batch_size', 2)),
            '--gradient_accumulation_steps', str(train_config.get('gradient_accumulation_steps', 8)),
            '--learning_rate', str(train_config.get('learning_rate', 1e-4)),
            '--max_length', str(train_config.get('max_length', 2048)),
            '--save_steps', str(train_config.get('save_steps', 100)),
            '--eval_steps', str(train_config.get('eval_steps', 100)),
            '--logging_steps', str(train_config.get('logging_steps', 10)),
            '--warmup_ratio', str(train_config.get('warmup_ratio', 0.03)),
            '--weight_decay', str(train_config.get('weight_decay', 0.1)),
        ]
        
        # LoRAç›¸å…³å‚æ•°
        if train_type in ['lora', 'qlora']:
            args.extend([
                '--lora_rank', str(train_config.get('lora_rank', 8)),
                '--lora_alpha', str(train_config.get('lora_alpha', 32)),
                '--lora_dropout', str(train_config.get('lora_dropout', 0.05)),
            ])
        
        # æ¢¯åº¦æ£€æŸ¥ç‚¹
        if train_config.get('gradient_checkpointing', True):
            args.append('--gradient_checkpointing')
        
        # DeepSpeedé…ç½®ï¼ˆå…¨å‚æ•°å¾®è°ƒï¼‰
        if train_type == 'full':
            deepspeed = train_config.get('deepspeed', 'zero2')
            if deepspeed:
                args.extend(['--deepspeed', deepspeed])
        
        # å¤šæ¨¡æ€ç‰¹æ®Šé…ç½®
        if train_type == 'multimodal':
            args.extend([
                '--lora_rank', str(train_config.get('lora_rank', 16)),
                '--lora_alpha', str(train_config.get('lora_alpha', 32)),
            ])
        
        return args
    
    def execute_training(self, train_config: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œè®­ç»ƒ
        Args:
            train_config: è®­ç»ƒé…ç½®
        Returns:
            str: è¾“å‡ºç›®å½•è·¯å¾„
        """
        train_type = train_config.get('train_type', 'lora')
        output_dir = train_config.get('output_dir', './output')
        
        self.logger.info(f"ğŸš€ å¼€å§‹{train_type.upper()}å¾®è°ƒè®­ç»ƒ...")
        self.logger.info(f"ğŸ“ æ¨¡å‹: {train_config.get('model')}")
        self.logger.info(f"ğŸ“Š æ•°æ®é›†: {train_config.get('dataset')}")
        self.logger.info(f"ğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
        
        # å‡†å¤‡è®­ç»ƒå‚æ•°
        train_args = self.prepare_training_args(train_config)
        
        # å¤‡ä»½åŸå§‹sys.argv
        original_argv = sys.argv.copy()
        
        try:
            # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°
            sys.argv = ['sft_main'] + train_args
            
            # æ‰§è¡Œè®­ç»ƒ
            self.logger.info("â³ å¼€å§‹æ‰§è¡Œè®­ç»ƒ...")
            result = sft_main()
            
            self.logger.info(f"âœ… {train_type.upper()}å¾®è°ƒå®Œæˆ")
            return str(output_dir)
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
            raise e
        finally:
            # æ¢å¤åŸå§‹å‚æ•°
            sys.argv = original_argv
    
    def train_lora(self, **kwargs) -> str:
        """LoRAå¾®è°ƒ"""
        config = {**self.config, **kwargs, 'train_type': 'lora'}
        return self.execute_training(config)
    
    def train_qlora(self, **kwargs) -> str:
        """QLoRAå¾®è°ƒ"""
        config = {**self.config, **kwargs, 'train_type': 'qlora'}
        # QLoRAçš„é»˜è®¤é…ç½®
        config.setdefault('per_device_train_batch_size', 1)
        config.setdefault('gradient_accumulation_steps', 16)
        return self.execute_training(config)
    
    def train_full_params(self, **kwargs) -> str:
        """å…¨å‚æ•°å¾®è°ƒ"""
        config = {**self.config, **kwargs, 'train_type': 'full'}
        # å…¨å‚æ•°å¾®è°ƒçš„é»˜è®¤é…ç½®
        config.setdefault('per_device_train_batch_size', 1)
        config.setdefault('gradient_accumulation_steps', 32)
        config.setdefault('learning_rate', 5e-5)
        return self.execute_training(config)
    
    def train_multimodal(self, **kwargs) -> str:
        """å¤šæ¨¡æ€å¾®è°ƒ"""
        config = {**self.config, **kwargs, 'train_type': 'multimodal'}
        # å¤šæ¨¡æ€å¾®è°ƒçš„é»˜è®¤é…ç½®
        config.setdefault('model', 'Qwen/Qwen2.5-VL-7B-Instruct')
        config.setdefault('dataset', ['AI-ModelScope/coco-en-2-zh#20000'])
        config.setdefault('lora_rank', 16)
        return self.execute_training(config)
    
    def run_training_from_config(self) -> str:
        """ä»é…ç½®æ–‡ä»¶è¿è¡Œè®­ç»ƒ"""
        if not self.config:
            raise ValueError("âŒ æœªæä¾›é…ç½®ä¿¡æ¯")
        
        train_type = self.config.get('train_type', 'lora')
        self.logger.info(f"ğŸ“‹ ä»é…ç½®è¿è¡Œ{train_type.upper()}è®­ç»ƒ")
        
        return self.execute_training(self.config)

class TrainingPresets:
    """è®­ç»ƒé¢„è®¾é…ç½®"""
    
    @staticmethod
    def get_lora_preset(model: str = "Qwen/Qwen2.5-7B-Instruct") -> Dict[str, Any]:
        """è·å–LoRAè®­ç»ƒé¢„è®¾"""
        return {
            'model': model,
            'train_type': 'lora',
            'dataset': ['AI-ModelScope/alpaca-gpt4-data-zh#1000'],
            'num_train_epochs': 3,
            'per_device_train_batch_size': 2,
            'gradient_accumulation_steps': 8,
            'learning_rate': 1e-4,
            'lora_rank': 8,
            'lora_alpha': 32,
            'lora_dropout': 0.05,
            'max_length': 2048,
            'save_steps': 100,
            'logging_steps': 10,
            'warmup_ratio': 0.03,
            'weight_decay': 0.1,
            'gradient_checkpointing': True,
        }
    
    @staticmethod
    def get_qlora_preset(model: str = "Qwen/Qwen2.5-7B-Instruct") -> Dict[str, Any]:
        """è·å–QLoRAè®­ç»ƒé¢„è®¾"""
        preset = TrainingPresets.get_lora_preset(model)
        preset.update({
            'train_type': 'qlora',
            'per_device_train_batch_size': 1,
            'gradient_accumulation_steps': 16,
        })
        return preset
    
    @staticmethod
    def get_full_preset(model: str = "Qwen/Qwen2.5-7B-Instruct") -> Dict[str, Any]:
        """è·å–å…¨å‚æ•°è®­ç»ƒé¢„è®¾"""
        return {
            'model': model,
            'train_type': 'full',
            'dataset': ['AI-ModelScope/alpaca-gpt4-data-zh#1000'],
            'num_train_epochs': 3,
            'per_device_train_batch_size': 1,
            'gradient_accumulation_steps': 32,
            'learning_rate': 5e-5,
            'max_length': 2048,
            'save_steps': 100,
            'logging_steps': 10,
            'warmup_ratio': 0.03,
            'weight_decay': 0.1,
            'gradient_checkpointing': True,
            'deepspeed': 'zero2',
        }
    
    @staticmethod
    def get_multimodal_preset(model: str = "Qwen/Qwen2.5-VL-7B-Instruct") -> Dict[str, Any]:
        """è·å–å¤šæ¨¡æ€è®­ç»ƒé¢„è®¾"""
        return {
            'model': model,
            'train_type': 'multimodal',
            'dataset': ['AI-ModelScope/coco-en-2-zh#20000'],
            'num_train_epochs': 3,
            'per_device_train_batch_size': 1,
            'gradient_accumulation_steps': 8,
            'learning_rate': 1e-4,
            'lora_rank': 16,
            'lora_alpha': 32,
            'max_length': 2048,
            'save_steps': 100,
            'logging_steps': 10,
        }

def create_trainer(config_path: Optional[str] = None) -> TrainingManager:
    """
    åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    Returns:
        TrainingManager: è®­ç»ƒç®¡ç†å™¨å®ä¾‹
    """
    return TrainingManager(config_path)

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ§ª è®­ç»ƒå™¨æµ‹è¯•...")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = create_trainer()
    
    # ä½¿ç”¨é¢„è®¾é…ç½®è¿›è¡ŒLoRAè®­ç»ƒ
    lora_config = TrainingPresets.get_lora_preset()
    lora_config['output_dir'] = './test_output'
    lora_config['dataset'] = ['AI-ModelScope/alpaca-gpt4-data-zh#100']  # å°æ•°æ®é›†ç”¨äºæµ‹è¯•
    
    print("ğŸ”§ LoRAè®­ç»ƒé…ç½®:")
    for key, value in lora_config.items():
        print(f"  {key}: {value}")
    
    # æ³¨æ„ï¼šè¿™é‡Œä¸å®é™…è¿è¡Œè®­ç»ƒï¼Œåªæ˜¯å±•ç¤ºé…ç½®
    print("âœ… è®­ç»ƒå™¨æ¨¡å—åŠ è½½æˆåŠŸ")