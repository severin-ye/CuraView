{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7284536d-0f0e-40f2-a12c-469ff5c2f3d4",
   "metadata": {},
   "source": [
    "# 10分钟改变大模型自我认知，定制“专属自己”的聊天机器人\n",
    "\n",
    "我们使用ms-swift对Qwen2.5-3B-Instruct进行自我认知微调。\n",
    "\n",
    "- 模型：https://modelscope.cn/models/Qwen/Qwen2.5-3B-Instruct\n",
    "\n",
    "- 自我认知数据集：https://modelscope.cn/datasets/swift/self-cognition\n",
    "\n",
    "- 训练框架：https://github.com/modelscope/ms-swift.git\n",
    "\n",
    "- 实验环境：A10、3090等（需显存资源12GB）\n",
    "\n",
    "这里给出了两种训练和推理的方式，分别是：使用命令行界面和使用Python。\n",
    "\n",
    "- 使用命令行界面：帮助开发者更快的将训练和推理跑起来。\n",
    "\n",
    "- 使用Python：帮助开发者了解训练和推理的一些细节，这对定制训练过程有很大帮助。\n",
    "\n",
    "准备好了吗？让我们开始这段旅程叭……\n",
    "\n",
    "## 安装 ms-swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e80a62-28b5-481b-918f-797125eaeb25",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install ms-swift -U\n",
    "%pip install transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a5ea5-dccb-4128-af56-c58b8c6a4885",
   "metadata": {},
   "source": [
    "## 使用Python\n",
    "\n",
    "\n",
    "#### 训练\n",
    "导入一些库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389e31e5-f00c-426c-875e-f85afea9040d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/hd/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO:swift] Successfully registered `/home/work/hd/.venv/lib/python3.10/site-packages/swift/llm/dataset/data/dataset_info.json`.\n",
      "[INFO:swift] Successfully registered `/home/work/hd/.venv/lib/python3.10/site-packages/swift/llm/dataset/data/dataset_info.json`.\n",
      "WARNING: BNB_CUDA_VERSION=123 environment variable detected; loading libbitsandbytes_cuda123.so.\n",
      "This can be used to load a bitsandbytes version built with a CUDA version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "\n",
      "WARNING: BNB_CUDA_VERSION=123 environment variable detected; loading libbitsandbytes_cuda123.so.\n",
      "This can be used to load a bitsandbytes version built with a CUDA version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "\n",
      "[INFO:swift] Global seed set to 42\n",
      "[INFO:swift] Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入操作系统相关的库\n",
    "import os\n",
    "# 设置CUDA可见设备为第0块GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# 从swift.llm模块导入模型和分词器加载函数\n",
    "# get_model_tokenizer: 获取模型和分词器\n",
    "# load_dataset: 加载数据集\n",
    "# get_template: 获取对话模板\n",
    "# EncodePreprocessor: 文本编码预处理器\n",
    "from swift.llm import get_model_tokenizer, load_dataset, get_template, EncodePreprocessor\n",
    "\n",
    "# 从swift.utils模块导入工具函数\n",
    "# get_logger: 获取日志记录器\n",
    "# get_model_parameter_info: 获取模型参数信息\n",
    "# plot_images: 绘制图像\n",
    "# seed_everything: 设置随机种子确保实验可重复\n",
    "from swift.utils import get_logger, get_model_parameter_info, plot_images, seed_everything\n",
    "\n",
    "# 从swift.trainers模块导入训练器和训练参数\n",
    "# Seq2SeqTrainer: 序列到序列训练器\n",
    "# Seq2SeqTrainingArguments: 序列到序列训练参数配置\n",
    "from swift.trainers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# 从functools导入partial函数，用于创建偏函数\n",
    "from functools import partial\n",
    "\n",
    "# 获取日志记录器实例\n",
    "logger = get_logger()\n",
    "# 设置全局随机种子为42，确保实验结果可重复\n",
    "seed_everything(42)\n",
    "\n",
    "# 注意：已移除LoRA相关导入\n",
    "# 不再需要: from swift.tuners import Swift, LoraConfig, find_all_linears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1e09b-3718-40c6-9bc4-83f1abe8ef62",
   "metadata": {},
   "source": [
    "设置训练的超参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d986b80b-b4eb-43db-b714-378081a33abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:swift] output_dir: /home/work/hd/2_core/1_train/output\n"
     ]
    }
   ],
   "source": [
    "# ========== 模型配置 ==========\n",
    "# 指定要使用的模型路径或模型ID\n",
    "model_id_or_path = '/home/work/hd/_models/base/qwen3-4b-thinking'  # model_id or model_path\n",
    "# 设置系统提示语，定义AI助手的基本行为\n",
    "system = 'You are a helpful assistant.'\n",
    "# 设置训练输出目录，保存模型检查点和日志\n",
    "output_dir = 'output'\n",
    "\n",
    "# ========== 数据集配置 ==========\n",
    "# 定义训练数据集列表，#后的数字表示使用该数据集的前N条数据\n",
    "# AI-ModelScope/alpaca-gpt4-data-zh: 中文指令数据集，使用前500条\n",
    "# AI-ModelScope/alpaca-gpt4-data-en: 英文指令数据集，使用前500条  \n",
    "# swift/self-cognition: 自我认知数据集，使用前500条\n",
    "dataset = ['AI-ModelScope/alpaca-gpt4-data-zh#500', 'AI-ModelScope/alpaca-gpt4-data-en#500',\n",
    "           'swift/self-cognition#500']  # dataset_id or dataset_path\n",
    "# 数据集随机种子，确保数据划分的可重复性\n",
    "data_seed = 42\n",
    "# 输入序列的最大长度（tokens数量）\n",
    "max_length = 2048\n",
    "# 验证集划分比例，0.01表示1%的数据用作验证集\n",
    "split_dataset_ratio = 0.01  # 切分验证集\n",
    "# 数据预处理时使用的进程数，加快数据处理速度\n",
    "num_proc = 4  # 预处理的进程数\n",
    "\n",
    "# ========== 自我认知数据集个性化配置 ==========\n",
    "# 替换自我认知数据集中的填充符：{{NAME}}, {{AUTHOR}}\n",
    "# 模型的中文名和英文名，用于替换数据集中的{{NAME}}占位符\n",
    "model_name = ['精衡', 'Jingheng']  # 模型的中文名和英文名\n",
    "# 模型作者的中文名和英文名，用于替换数据集中的{{AUTHOR}}占位符\n",
    "model_author = ['叶博韬', 'YE SEVERIN']  # 模型作者的中文名和英文名\n",
    "\n",
    "# ========== 全参数微调配置 ==========\n",
    "# 注意：全参数微调将训练模型的所有参数，需要更大的显存和更长的训练时间\n",
    "# 建议降低学习率和批次大小以避免训练不稳定\n",
    "\n",
    "# ========== 训练超参数配置 ==========\n",
    "# 创建序列到序列训练参数对象\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    # 模型检查点和日志的输出目录\n",
    "    output_dir=output_dir,\n",
    "    # 学习率，全参数微调使用更小的学习率\n",
    "    learning_rate=5e-6,  # 从1e-4降低到5e-6\n",
    "    # 每个GPU上的训练批次大小，全参数微调需要更小的批次\n",
    "    per_device_train_batch_size=1,  # 可能需要进一步降低\n",
    "    # 每个GPU上的验证批次大小\n",
    "    per_device_eval_batch_size=1,\n",
    "    # 启用梯度检查点，节省显存但增加计算时间\n",
    "    gradient_checkpointing=True,\n",
    "    # 权重衰减系数，防止过拟合的正则化技术\n",
    "    weight_decay=0.1,\n",
    "    # 学习率调度器类型，cosine表示余弦退火调度\n",
    "    lr_scheduler_type='cosine',\n",
    "    # 预热比例，训练初期逐渐增加学习率的步数占总步数的比例\n",
    "    warmup_ratio=0.05,\n",
    "    # 日志记录工具，tensorboard用于可视化训练过程\n",
    "    report_to=['tensorboard'],\n",
    "    # 是否在第一步就开始记录日志\n",
    "    logging_first_step=True,\n",
    "    # 模型保存策略，'steps'表示按步数保存\n",
    "    save_strategy='steps',\n",
    "    # 每隔50步保存一次模型检查点\n",
    "    save_steps=50,\n",
    "    # 模型评估策略，'steps'表示按步数评估\n",
    "    eval_strategy='steps',\n",
    "    # 每隔50步进行一次模型评估\n",
    "    eval_steps=50,\n",
    "    # 梯度累积步数，可能需要增加以补偿更小的批次大小\n",
    "    gradient_accumulation_steps=32,  # 从16增加到32\n",
    "    # 训练轮数，全参数微调通常需要更少的epoch\n",
    "    num_train_epochs=1,\n",
    "    # 选择最佳模型的评估指标，'loss'表示以损失函数为准\n",
    "    metric_for_best_model='loss',\n",
    "    # 最多保存的检查点数量，超过后删除最旧的\n",
    "    save_total_limit=2,\n",
    "    # 每隔5步记录一次训练日志\n",
    "    logging_steps=5,\n",
    "    # 数据加载器使用的工作进程数\n",
    "    dataloader_num_workers=1,\n",
    "    # 数据相关的随机种子\n",
    "    data_seed=data_seed,\n",
    "    # 全参数微调专用配置\n",
    "    # 启用BF16混合精度训练以节省显存（适用于BFloat16模型）\n",
    "    bf16=True,  # 使用bf16而不是fp16，适配BFloat16模型\n",
    "    # 设置最大梯度范数，防止梯度爆炸\n",
    "    max_grad_norm=1.0,\n",
    "    # 禁用FP16（因为我们使用BF16）\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "# 将输出目录转换为绝对路径\n",
    "output_dir = os.path.abspath(os.path.expanduser(output_dir))\n",
    "# 记录输出目录的绝对路径\n",
    "logger.info(f'output_dir: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91bf28-fec1-4a80-ba43-10b3f75699c3",
   "metadata": {},
   "source": [
    "获取模型和对话template，进行全参数微调："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade53c46-aef5-4cde-83c4-1d7ba781a155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n",
      "[INFO:swift] model_kwargs: {'device_map': 'cuda:0'}\n",
      "[INFO:swift] model_kwargs: {'device_map': 'cuda:0'}\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n",
      "[INFO:swift] model_info: ModelInfo(model_type='qwen3_thinking', model_dir='/home/work/hd/_models/base/qwen3-4b-thinking', torch_dtype=torch.bfloat16, max_model_len=262144, quant_method=None, quant_bits=None, rope_scaling=None, is_moe_model=False, config=Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 9728,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 262144,\n",
      "  \"max_window_layers\": 36,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 36,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 5000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      ", task_type='causal_lm', num_labels=None)\n",
      "[INFO:swift] default_system: 'You are a helpful assistant.'\n",
      "[INFO:swift] max_length: 2048\n",
      "[INFO:swift] response_prefix: '<think>\\n'\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n",
      "[INFO:swift] model_info: ModelInfo(model_type='qwen3_thinking', model_dir='/home/work/hd/_models/base/qwen3-4b-thinking', torch_dtype=torch.bfloat16, max_model_len=262144, quant_method=None, quant_bits=None, rope_scaling=None, is_moe_model=False, config=Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 9728,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 262144,\n",
      "  \"max_window_layers\": 36,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 36,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 5000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      ", task_type='causal_lm', num_labels=None)\n",
      "[INFO:swift] default_system: 'You are a helpful assistant.'\n",
      "[INFO:swift] max_length: 2048\n",
      "[INFO:swift] response_prefix: '<think>\\n'\n",
      "[INFO:swift] agent_template: hermes\n",
      "[INFO:swift] model: Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 2560)\n",
      "    (layers): ModuleList(\n",
      "      (0-35): 36 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
      ")\n",
      "[INFO:swift] model_parameter_info: Qwen3ForCausalLM: 4022.4681M Params (4022.4681M Trainable [100.0000%]), 0.0001M Buffers.\n",
      "[INFO:swift] agent_template: hermes\n",
      "[INFO:swift] model: Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 2560)\n",
      "    (layers): ModuleList(\n",
      "      (0-35): 36 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
      ")\n",
      "[INFO:swift] model_parameter_info: Qwen3ForCausalLM: 4022.4681M Params (4022.4681M Trainable [100.0000%]), 0.0001M Buffers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== 模型和分词器加载 ==========\n",
    "# 加载指定路径的模型和分词器，指定模型类型为qwen3_thinking\n",
    "# model_type参数用于区分同一目录下的不同模型变体\n",
    "model, tokenizer = get_model_tokenizer(model_id_or_path, model_type='qwen3_thinking')\n",
    "# 打印模型的基本信息（架构、参数量等）\n",
    "logger.info(f'model_info: {model.model_info}')\n",
    "\n",
    "# ========== 对话模板配置 ==========\n",
    "# 获取模型对应的对话模板，用于格式化输入输出\n",
    "# model.model_meta.template: 模型元数据中定义的模板类型\n",
    "# default_system: 设置默认的系统提示语\n",
    "# max_length: 限制输入序列的最大长度\n",
    "template = get_template(model.model_meta.template, tokenizer, default_system=system, max_length=max_length)\n",
    "# 将模板设置为训练模式，这会影响模板的行为（如是否包含特殊token）\n",
    "template.set_mode('train')\n",
    "\n",
    "# ========== 全参数微调配置 ==========\n",
    "# 注意：已移除LoRA相关配置，现在将进行全参数微调\n",
    "# 全参数微调会训练模型的所有权重，而不仅仅是添加的适配器\n",
    "\n",
    "# 不再需要以下LoRA相关代码：\n",
    "# - from swift.tuners import Swift, LoraConfig\n",
    "# - target_modules = find_all_linears(model)\n",
    "# - lora_config = LoraConfig(...)\n",
    "# - model = Swift.prepare_model(model, lora_config)\n",
    "\n",
    "# ========== 模型信息输出 ==========\n",
    "# 打印完整的模型结构（全参数微调版本，无LoRA层）\n",
    "logger.info(f'model: {model}')\n",
    "# 获取并打印模型参数统计信息（总参数量、可训练参数量等）\n",
    "model_parameter_info = get_model_parameter_info(model)\n",
    "logger.info(f'model_parameter_info: {model_parameter_info}')\n",
    "\n",
    "# ========== 显存优化设置 ==========\n",
    "# 对于全参数微调，建议启用以下优化设置\n",
    "# 1. 启用梯度检查点（已在training_args中设置）\n",
    "# 2. 启用FP16混合精度训练（已在training_args中设置）\n",
    "# 3. 确保模型在训练前处于正确状态\n",
    "model.train()  # 确保模型处于训练模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b77fe-5048-4323-9a57-c1f7a4042334",
   "metadata": {},
   "source": [
    "下载并载入数据集，并切分成训练集和验证集，\n",
    "\n",
    "然后将文本编码成tokens："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638d3513-e734-4307-b070-178a4f0128b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:swift] SelfCognitionPreprocessor has been successfully configured with name: ['精衡', 'Jingheng'], author: ['叶博韬', 'YE SEVERIN'].\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: AI-ModelScope/alpaca-gpt4-data-zh\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: AI-ModelScope/alpaca-gpt4-data-zh\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: AI-ModelScope/alpaca-gpt4-data-en\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: AI-ModelScope/alpaca-gpt4-data-en\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: swift/self-cognition\n",
      "[INFO:swift] Downloading the dataset from ModelScope, dataset_id: swift/self-cognition\n",
      "[WARNING:swift] dataset_sample:499 is greater than len(dataset):107, repeated sampling will be performed.\n",
      "[INFO:swift] train_dataset: Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 1489\n",
      "})\n",
      "[INFO:swift] val_dataset: Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 11\n",
      "})\n",
      "[WARNING:swift] dataset_sample:499 is greater than len(dataset):107, repeated sampling will be performed.\n",
      "[INFO:swift] train_dataset: Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 1489\n",
      "})\n",
      "[INFO:swift] val_dataset: Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 11\n",
      "})\n",
      "[INFO:swift] train_dataset[0]: {'messages': [{'role': 'user', 'content': '保持健康的三个提示。', 'loss': None}, {'role': 'assistant', 'content': '以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\\n\\n2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\\n\\n3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。', 'loss': None}]}\n",
      "[INFO:swift] train_dataset[0]: {'messages': [{'role': 'user', 'content': '保持健康的三个提示。', 'loss': None}, {'role': 'assistant', 'content': '以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\\n\\n2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\\n\\n3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。', 'loss': None}]}\n",
      "[INFO:swift] encoded_train_dataset[0]: {'input_ids': [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 100662, 108136, 101124, 45139, 1773, 151645, 198, 151644, 77091, 198, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645], 'length': 149}\n",
      "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 100662, 108136, 101124, 45139, 1773, 151645, 198, 151644, 77091, 198, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645]\n",
      "[INFO:swift] [INPUT] <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "保持健康的三个提示。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "以下是保持健康的三个提示：\n",
      "\n",
      "1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\n",
      "\n",
      "2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\n",
      "\n",
      "3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。<|im_end|>\n",
      "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645]\n",
      "[INFO:swift] [LABELS] [-100 * 24]以下是保持健康的三个提示：\n",
      "\n",
      "1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\n",
      "\n",
      "2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\n",
      "\n",
      "3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。<|im_end|>\n",
      "[INFO:swift] encoded_train_dataset[0]: {'input_ids': [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 100662, 108136, 101124, 45139, 1773, 151645, 198, 151644, 77091, 198, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645], 'length': 149}\n",
      "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 100662, 108136, 101124, 45139, 1773, 151645, 198, 151644, 77091, 198, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645]\n",
      "[INFO:swift] [INPUT] <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "保持健康的三个提示。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "以下是保持健康的三个提示：\n",
      "\n",
      "1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\n",
      "\n",
      "2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\n",
      "\n",
      "3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。<|im_end|>\n",
      "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 114566, 100662, 108136, 101124, 45139, 48443, 16, 13, 220, 100662, 101099, 99600, 1773, 101922, 99190, 102618, 106214, 101079, 3837, 29524, 111261, 5373, 107530, 57191, 107140, 3837, 26232, 101902, 114718, 99722, 3837, 101138, 105640, 101102, 90395, 105767, 101940, 107235, 3407, 17, 13, 4891, 251, 229, 99967, 104579, 1773, 101922, 105086, 104838, 9370, 104451, 5373, 104618, 5373, 35987, 100203, 52853, 33108, 105349, 104982, 99285, 9370, 107151, 102153, 3837, 101153, 44636, 100443, 5373, 44636, 105349, 33108, 101130, 101083, 3837, 23031, 100662, 108136, 104579, 100784, 3407, 18, 13, 10236, 251, 94, 101519, 103119, 1773, 105552, 113357, 99722, 107940, 3837, 113459, 101922, 50511, 101907, 220, 22, 12, 23, 58230, 237, 13343, 9370, 105552, 1773, 104205, 105552, 105767, 106104, 101950, 3837, 101902, 101099, 102005, 90395, 100627, 108260, 33108, 118836, 1773, 151645]\n",
      "[INFO:swift] [LABELS] [-100 * 24]以下是保持健康的三个提示：\n",
      "\n",
      "1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游泳，能促进心血管健康，增强肌肉力量，并有助于减少体重。\n",
      "\n",
      "2. 均衡饮食。每天食用新鲜的蔬菜、水果、全谷物和脂肪含量低的蛋白质食物，避免高糖、高脂肪和加工食品，以保持健康的饮食习惯。\n",
      "\n",
      "3. 睡眠充足。睡眠对人体健康至关重要，成年人每天应保证 7-8 小时的睡眠。良好的睡眠有助于减轻压力，促进身体恢复，并提高注意力和记忆力。<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "# ========== 数据集加载和划分 ==========\n",
    "# 加载指定的数据集并自动划分为训练集和验证集\n",
    "# dataset: 数据集列表，包含中文、英文指令数据和自我认知数据\n",
    "# split_dataset_ratio: 验证集比例（0.01 = 1%）\n",
    "# num_proc: 并行处理进程数，加快数据加载速度\n",
    "# model_name/model_author: 用于替换自我认知数据集中的{{NAME}}和{{AUTHOR}}占位符\n",
    "# seed: 随机种子，确保数据划分的可重复性\n",
    "train_dataset, val_dataset = load_dataset(dataset, split_dataset_ratio=split_dataset_ratio, num_proc=num_proc,\n",
    "        model_name=model_name, model_author=model_author, seed=data_seed)\n",
    "\n",
    "# ========== 数据集信息输出 ==========\n",
    "# 打印训练集的基本信息（数据条数、格式等）\n",
    "logger.info(f'train_dataset: {train_dataset}')\n",
    "# 打印验证集的基本信息\n",
    "logger.info(f'val_dataset: {val_dataset}')\n",
    "# 打印训练集第一条原始数据样本，查看数据格式和内容\n",
    "logger.info(f'train_dataset[0]: {train_dataset[0]}')\n",
    "\n",
    "# ========== 数据编码预处理 ==========\n",
    "# 创建编码预处理器，将文本转换为模型可理解的token序列\n",
    "# template: 使用之前配置的对话模板来格式化数据\n",
    "# 对训练集进行编码处理：文本 -> token IDs\n",
    "train_dataset = EncodePreprocessor(template=template)(train_dataset, num_proc=num_proc)\n",
    "# 对验证集进行编码处理：文本 -> token IDs\n",
    "val_dataset = EncodePreprocessor(template=template)(val_dataset, num_proc=num_proc)\n",
    "# 打印编码后的训练集第一条数据，查看token化后的格式\n",
    "logger.info(f'encoded_train_dataset[0]: {train_dataset[0]}')\n",
    "\n",
    "# ========== 样本展示 ==========\n",
    "# 使用模板的打印功能展示一条完整的训练样本\n",
    "# 这会显示格式化后的输入输出对，包括系统提示、用户输入、模型回答等\n",
    "template.print_inputs(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f90f0e-8da2-42ab-8f5b-2a39da539a5e",
   "metadata": {},
   "source": [
    "初始化trainer并开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b1a9c-cf0b-4985-9dac-1bc9b1d12473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "Train:   0%|          | 0/47 [08:19<?, ?it/s]\n",
      "Train:   0%|          | 0/47 [00:00<?, ?it/s]\n",
      "Train:   2%|▏         | 1/47 [00:05<04:30,  5.89s/it]\n",
      "Train:   2%|▏         | 1/47 [00:05<04:30,  5.89s/it] \n",
      "Train:   2%|▏         | 1/47 [00:05<04:30,  5.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.69011736, 'grad_norm': 5.96875, 'learning_rate': 1.67e-06, 'token_acc': 0.57945684, 'epoch': 0.02, 'global_step/max_steps': '1/47', 'percentage': '2.13%', 'elapsed_time': '5s', 'remaining_time': '4m 32s', 'memory(GiB)': 60.49, 'train_speed(iter/s)': 0.169098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   4%|▍         | 2/47 [00:11<04:22,  5.84s/it]"
     ]
    }
   ],
   "source": [
    "# ========== 模型训练前准备 ==========\n",
    "# 启用输入梯度计算，这是使用梯度检查点（gradient checkpointing）时的必要设置\n",
    "# 梯度检查点可以节省显存，但需要在前向传播时重新计算某些中间激活值\n",
    "model.enable_input_require_grads()  # 兼容gradient checkpointing\n",
    "\n",
    "# ========== 训练器初始化 ==========\n",
    "# 创建序列到序列训练器对象，配置所有训练相关组件\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,                        # 要训练的模型（全参数微调版本）\n",
    "    args=training_args,                 # 训练参数配置（学习率、批次大小、保存策略等）\n",
    "    data_collator=template.data_collator,  # 数据整理器，用于将批次数据转换为模型输入格式\n",
    "    train_dataset=train_dataset,        # 训练数据集（已编码为token序列）\n",
    "    eval_dataset=val_dataset,           # 验证数据集（用于评估模型性能）\n",
    "    template=template,                  # 对话模板（用于格式化输入输出）\n",
    ")\n",
    "\n",
    "# ========== 开始训练 ==========\n",
    "# 启动训练过程，这将执行以下步骤：\n",
    "# 1. 前向传播：计算模型输出和损失\n",
    "# 2. 反向传播：计算梯度\n",
    "# 3. 参数更新：使用优化器更新所有模型权重（全参数微调）\n",
    "# 4. 定期保存检查点和记录日志\n",
    "# 5. 定期在验证集上评估模型性能\n",
    "trainer.train()\n",
    "\n",
    "# ========== 训练完成后处理 ==========\n",
    "# 获取最后保存的模型检查点路径\n",
    "# trainer.state.last_model_checkpoint 包含了训练过程中最后一次保存的模型路径\n",
    "last_model_checkpoint = trainer.state.last_model_checkpoint\n",
    "# 记录最终模型检查点的位置，用于后续推理\n",
    "logger.info(f'last_model_checkpoint: {last_model_checkpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d178b52-fedb-4819-a463-27b624f310ff",
   "metadata": {},
   "source": [
    "可视化训练的loss。其中浅黄色线条代表真实loss值，黄色线条代表经过0.9平滑系数平滑后的loss值。\n",
    "\n",
    "你也可以使用tensorboard进行实时可视化，在命令行输入`tensorboard --logdir '{output_dir}/runs'`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92274822-0837-4521-9ad9-840ec0425d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.join(output_dir, 'images')\n",
    "logger.info(f'images_dir: {images_dir}')\n",
    "plot_images(images_dir, training_args.logging_dir, ['train/loss'], 0.9)  # 保存图片\n",
    "\n",
    "# 展示图片\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "image = Image.open(os.path.join(images_dir, 'train_loss.png'))\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2216b-02a7-45f2-88ec-0d5c7b273de9",
   "metadata": {},
   "source": [
    "#### 微调后推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6217b-2647-41f4-b6cc-32275dd829f3",
   "metadata": {},
   "source": [
    "导入一些库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32208bd0-806e-4de5-86fc-1017366ab4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 推理环境设置 ==========\n",
    "# 导入操作系统相关库\n",
    "import os\n",
    "# 设置CUDA可见设备为第0块GPU（与训练时保持一致）\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# ========== 推理相关库导入 ==========\n",
    "# 从swift.llm模块导入推理相关的核心类和函数\n",
    "from swift.llm import (\n",
    "    InferEngine,      # 推理引擎基类，定义推理接口\n",
    "    InferRequest,     # 推理请求对象，封装用户输入和配置\n",
    "    PtEngine,         # PyTorch推理引擎，用于加载和运行PyTorch模型\n",
    "    RequestConfig,    # 请求配置对象，设置生成参数（温度、最大长度等）\n",
    "    get_template      # 获取对话模板函数，用于格式化输入输出\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c0967-2a57-4dc4-aaa0-62e23f53d3cd",
   "metadata": {},
   "source": [
    "设置推理的超参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229fa94-1aab-4727-930d-e354bdf30986",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-12-25T16:56:32.156242Z",
     "iopub.status.busy": "2024-12-25T16:56:32.155674Z",
     "iopub.status.idle": "2024-12-25T16:56:32.159195Z",
     "shell.execute_reply": "2024-12-25T16:56:32.158698Z",
     "shell.execute_reply.started": "2024-12-25T16:56:32.156217Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 微调后模型路径配置 ==========\n",
    "# 指定训练完成后保存的模型检查点路径\n",
    "# 注意：全参数微调保存的是完整的模型权重，不是LoRA适配器\n",
    "# 格式为 output/vx-xxx/checkpoint-xxx\n",
    "last_model_checkpoint = 'output/vx-xxx/checkpoint-xxx'\n",
    "\n",
    "# ========== 推理模型配置 ==========\n",
    "# 对于全参数微调，直接使用微调后的完整模型路径\n",
    "# 不再需要指定基础模型 + LoRA适配器的组合方式\n",
    "model_id_or_path = last_model_checkpoint  # 直接使用微调后的完整模型\n",
    "# 设置系统提示语，定义AI助手的行为特征\n",
    "system = 'You are a helpful assistant.'\n",
    "# 指定推理后端类型，'pt'表示使用PyTorch后端\n",
    "infer_backend = 'pt'\n",
    "\n",
    "# ========== 文本生成参数配置 ==========\n",
    "# 设置生成文本的最大新token数量（不包括输入部分）\n",
    "max_new_tokens = 10000\n",
    "# 设置生成温度，控制文本生成的随机性\n",
    "# temperature=0: 确定性生成，总是选择概率最高的token\n",
    "# temperature>0: 随机性生成，值越大越随机\n",
    "temperature = 0\n",
    "# 是否启用流式输出，True表示逐token生成并实时返回\n",
    "# 流式输出可以提供更好的用户体验，类似ChatGPT的打字效果\n",
    "stream = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a3bf9-c321-4f33-9251-944059537a4d",
   "metadata": {},
   "source": [
    "获取推理引擎，载入全参数微调后的完整模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bcc49e-c354-48bf-b869-3db603e8d648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== 推理引擎初始化 ==========\n",
    "# 创建PyTorch推理引擎，直接加载微调后的完整模型\n",
    "# 全参数微调后，模型的所有权重都已经更新，不需要额外的适配器\n",
    "# model_id_or_path: 微调后的完整模型路径\n",
    "engine = PtEngine(model_id_or_path)  # 不再需要adapters参数\n",
    "\n",
    "# ========== 对话模板配置 ==========\n",
    "# 获取与推理引擎模型匹配的对话模板\n",
    "# engine.model.model_meta.template: 从模型元数据中获取模板类型\n",
    "# engine.tokenizer: 使用推理引擎的分词器\n",
    "# default_system: 设置默认的系统提示语\n",
    "template = get_template(engine.model.model_meta.template, engine.tokenizer, default_system=system)\n",
    "\n",
    "# ========== 设置默认模板 ==========\n",
    "# 将配置好的模板设置为推理引擎的默认模板\n",
    "# 这样在调用engine.infer()时会自动使用此模板格式化输入输出\n",
    "# 也可以在每次调用engine.infer()时单独传入template参数\n",
    "engine.default_template = template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a01fa0-673d-44f3-9891-b31faaf63b6f",
   "metadata": {},
   "source": [
    "开始推理..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d657572-67a1-4224-ac37-6fefee54d179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_list = [\n",
    "    'who are you?',\n",
    "    \"晚上睡不着觉怎么办？\",\n",
    "    '你是谁训练的？',\n",
    "]\n",
    "\n",
    "def infer_stream(engine: InferEngine, infer_request: InferRequest):\n",
    "    request_config = RequestConfig(max_tokens=max_new_tokens, temperature=temperature, stream=True)\n",
    "    gen_list = engine.infer([infer_request], request_config)\n",
    "    query = infer_request.messages[0]['content']\n",
    "    print(f'query: {query}\\nresponse: ', end='')\n",
    "    for resp in gen_list[0]:\n",
    "        if resp is None:\n",
    "            continue\n",
    "        print(resp_list[0].choices[0].delta.content, end='', flush=True)\n",
    "    print()\n",
    "\n",
    "def infer(engine: InferEngine, infer_request: InferRequest):\n",
    "    request_config = RequestConfig(max_tokens=max_new_tokens, temperature=temperature)\n",
    "    resp_list = engine.infer([infer_request], request_config)\n",
    "    query = infer_request.messages[0]['content']\n",
    "    response = resp_list[0].choices[0].message.content\n",
    "    print(f'query: {query}')\n",
    "    print(f'response: {response}')\n",
    "\n",
    "infer_func = infer_stream if stream else infer\n",
    "for query in query_list:\n",
    "    infer_func(engine, InferRequest(messages=[{'role': 'user', 'content': query}]))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870a41b-d05a-49eb-ae65-c8674cfb3d65",
   "metadata": {},
   "source": [
    "## Web-UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc891d97-4be5-43e0-8a39-9c805d242059",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# ========== Web-UI启动命令 ==========\n",
    "# 使用全参数微调后的完整模型启动Web界面\n",
    "# 注意：需要将 output/vx-xxx/checkpoint-xxx 替换为实际的检查点路径\n",
    "\n",
    "# 方法1：查看实际的检查点路径\n",
    "print(f\"实际的检查点路径: {last_model_checkpoint}\")\n",
    "\n",
    "# 方法2：启动Web-UI（需要替换为实际路径）\n",
    "# 全参数微调后，直接使用完整模型路径，不需要指定适配器\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "swift web-ui \\\n",
    "    --model_id_or_path {last_model_checkpoint} \\\n",
    "    --model_type qwen3_thinking \\\n",
    "    --temperature 0 \\\n",
    "    --infer_backend pt \\\n",
    "    --max_new_tokens 2048\n",
    "\n",
    "# 注意：全参数微调版本不需要 --adapters 参数\n",
    "# 因为模型的所有权重都已经在微调过程中更新了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
