hd/
├── 0_configs/                                              # 📁 层级0：配置层（全局与模块参数）
│   ├── 0_train_config.json                                 # 模型训练配置（batch_size, lr, dataset_path等）
│   ├── 1_model_config.json                                 # 模型结构与tokenizer配置
│   ├── 2_deploy_config.json                                # 部署配置（端口号、GPU分配策略）
│   └── agents/                                             # 子目录：Agent层专属配置
│       ├── 0_rag_agent.json                                # RAGAgent配置（retrieval_topk, temperature等）
│       ├── 1_preference_agent.json                         # PreferenceAgent配置（多模型投票策略）
│       └── 2_medical_agent.json                            # 医疗Agent配置（Prompt模板、检查表）
│
├── 1_utils/                                                # 📁 层级1：工具层（通用功能，供全层使用）
│   ├── 0_config_loader.py                                  # 读取/合并JSON配置文件，支持路径自动解析
│   ├── 1_logger.py                                         # 日志记录模块（标准化输出与日志级别）
│   ├── 2_gpu_manager.py                                    # GPU显存分配与监控，支持自动分配最空闲设备
│   ├── 3_io_utils.py                                       # 文件IO操作（缓存、JSON/YAML读写）
│   ├── 4_metrics.py                                        # 常见评估指标（BLEU, ROUGE, METEOR, Loss等）
│   └── 5_decorators.py                                     # 函数装饰器库（性能计时、重试、异常捕获等）
│
├── 2_core/                                                 # 📁 层级2：核心逻辑层（算法与底层执行）
│   ├── training/                                           # 模型训练逻辑
│   │   ├── 0_dataset_loader.py                             # 数据集加载与预处理
│   │   ├── 1_loss_functions.py                             # 自定义损失函数（KL, GRPO, DPO等）
│   │   └── 2_finetune_trainer.py                           # 微调主逻辑（LoRA/QLoRA/Deepspeed支持）
│   │
│   ├── inference/                                          # 模型推理逻辑
│   │   ├── 0_smart_gpu_inference.py                        # 智能推理器（自动显存管理）
│   │   ├── 1_inference_runner.py                           # 推理主流程（Batch/Stream模式）
│   │   └── 2_reranker.py                                   # 输出重排序模块（Reranker模型或Embedding排序）
│   │
│   ├── deployment/                                         # 模型部署逻辑
│   │   ├── 0_deploy_model.py                               # 部署主脚本（模型加载 + API注册）
│   │   ├── 1_version_manager.py                            # 模型版本管理（回滚与切换）
│   │   └── 2_health_check.py                               # 健康检测逻辑（心跳与显存状态）
│   │
│   └── evaluation/                                         # 模型评估逻辑
│       ├── 0_eval_metrics.py                               # 评估指标计算实现
│       ├── 1_evaluator.py                                  # 统一评估入口（调用各指标模块）
│       └── 2_test_runner.py                                # 自动化测试脚本执行与日志收集
│
├── 3_agents/                                               # 📁 层级3：智能体层（调度与任务编排）
│   ├── 0_base_agent.py                                     # 抽象基类：定义Agent统一接口(run, load_config等)
│   ├── 1_rag_agent.py                                      # 检索增强Agent（RAG + LLM推理整合）
│   ├── 2_preference_agent.py                               # 偏好对齐Agent（多模型投票与输出融合）
│   ├── 3_medical_agent.py                                  # 医疗问答Agent（EHR摘要/报告解释）
│   ├── 4_workflow_agent.py                                 # 多阶段任务链（Prompt Chaining / Reflection等）
│   └── 5_registry.py                                       # Agent注册表与工厂方法（动态加载Agent）
│
├── 4_scripts/                                              # 📁 层级4：执行入口层（命令行与实验入口）
│   ├── 0_train.py                                          # 启动训练流程（读取配置并调用2_core.training）
│   ├── 1_infer.py                                          # 推理命令行入口（输入prompt执行生成）
│   ├── 2_deploy.py                                         # 部署模型到服务端（REST/gRPC启动）
│   ├── 3_evaluate.py                                       # 模型评估脚本入口（调用evaluation模块）
│   ├── 4_run_agent.py                                      # 通用Agent启动器（通过参数选择Agent）
│   └── 5_debug_gpu.py                                      # GPU诊断脚本（打印显存状态/性能测试）
│
├── 5_models/                                               # 📁 层级5：模型权重层（原始模型与tokenizer）
│   ├── Qwen3-30B-A3B-Thinking-2507/                        # 主模型（完整权重）
│   │   ├── config.json
│   │   ├── generation_config.json
│   │   ├── merges.txt
│   │   ├── tokenizer.json
│   │   ├── model-00001-of-00016.safetensors
│   │   └── ...
│   └── Qwen3-4B-Thinking-2507-FP8/                         # 轻量FP8推理模型
│       ├── config.json
│       ├── model.safetensors
│       └── tokenizer.json
│
├── 6_output/                                               # 📁 层级6：输出层（运行日志与结果）
│   ├── Qwen3-8B-Base/
│   │   └── v0-20250929-101225/
│   │       └── runs/run.log                               # TensorBoard/训练日志
│   ├── inference_results/                                  # 推理输出存档
│   └── eval_reports/                                       # 模型评估报告
│
├── 7_docs/                                                 # 📁 层级7：文档层（说明书与研究报告）
│   ├── 0_MS-SWIFT_使用指南.md                              # MS-SWIFT工具链使用教程
│   ├── 1_Qwen3高效微调.ipynb                               # 微调实践Notebook
│   ├── 2_环境修复指南.md                                   # 环境配置与依赖修复手册
│   ├── 3_推理示例.ipynb                                   # 推理与评估示例
│   └── 4_架构设计说明.md                                   # 解释分层架构与依赖关系
│
├── requirements.txt                                        # Python依赖声明文件
├── README.md                                               # 项目总说明（架构 + 使用方式）
└── __init__.py                                             # 将项目标记为Python包
