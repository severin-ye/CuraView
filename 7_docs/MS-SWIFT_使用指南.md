# MS-SWIFT æœ¬åœ°æ¨¡å‹ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [ç®€ä»‹](#ç®€ä»‹)
2. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
3. [å®‰è£…é…ç½®](#å®‰è£…é…ç½®)
4. [æœ¬åœ°æ¨¡å‹ç®¡ç†](#æœ¬åœ°æ¨¡å‹ç®¡ç†)
5. [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
6. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
7. [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## ğŸ“– ç®€ä»‹

MS-SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning) æ˜¯é˜¿é‡Œå·´å·´ ModelScope ç¤¾åŒºæä¾›çš„å®˜æ–¹æ¡†æ¶ï¼Œç”¨äºå¤§è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„å¾®è°ƒå’Œéƒ¨ç½²ã€‚

### æ ¸å¿ƒç‰¹æ€§
- ğŸš€ æ”¯æŒ 500+ å¤§è¯­è¨€æ¨¡å‹å’Œ 200+ å¤šæ¨¡æ€æ¨¡å‹
- ğŸ¯ æ”¯æŒè®­ç»ƒã€æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–ã€éƒ¨ç½²å…¨æµç¨‹
- ğŸ’¡ æ”¯æŒ LoRAã€QLoRAã€DoRA ç­‰è½»é‡åŒ–è®­ç»ƒæ–¹æ³•
- ğŸ”§ æä¾› Web UI ç•Œé¢å’Œä¸°å¯Œçš„æœ€ä½³å®è·µ

---

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚
- **Python**: 3.10+ (æ¨è)
- **CUDA**: æ”¯æŒçš„ CUDA ç‰ˆæœ¬
- **å†…å­˜**: æ ¹æ®æ¨¡å‹å¤§å°è°ƒæ•´
- **æ˜¾å­˜**: 4Bæ¨¡å‹è‡³å°‘8GBï¼Œ30Bæ¨¡å‹å»ºè®®40GB+

### ç¡¬ä»¶æ”¯æŒ
- CPUã€RTXç³»åˆ—ã€T4/V100ã€A10/A100/H100
- Ascend NPUã€MPS ç­‰

---

## ğŸ“¦ å®‰è£…é…ç½®

### 1. åŸºç¡€å®‰è£…

```bash
# ä½¿ç”¨ pip å®‰è£…
pip install ms-swift -U

# æˆ–è€…ä»æºç å®‰è£…
git clone https://github.com/modelscope/ms-swift.git
cd ms-swift
pip install -e .
```

### 2. ç¯å¢ƒä¾èµ–

ç¡®ä¿ä»¥ä¸‹å…³é”®ä¾èµ–å·²æ­£ç¡®å®‰è£…ï¼š

```bash
# æ ¸å¿ƒä¾èµ–
pip install torch>=2.0
pip install transformers>=4.33
pip install modelscope>=1.23
pip install peft>=0.11,<0.18

# å¯é€‰ä¾èµ–ï¼ˆæ ¹æ®éœ€è¦å®‰è£…ï¼‰
pip install flash_attn  # æ³¨æ„åŠ›ä¼˜åŒ–
pip install vllm>=0.5.1  # æ¨ç†åŠ é€Ÿ
pip install deepspeed>=0.14  # åˆ†å¸ƒå¼è®­ç»ƒ
pip install gradio  # Web UI
```

### 3. ä¾èµ–é—®é¢˜è§£å†³

å¦‚æœé‡åˆ° `bitsandbytes` æˆ– `triton` ç›¸å…³é”™è¯¯ï¼š

```bash
# é‡æ–°å®‰è£… bitsandbytes
pip uninstall bitsandbytes
pip install bitsandbytes

# æˆ–è€…ç¦ç”¨é‡åŒ–åŠŸèƒ½
export USE_BNB=0
```

---

## ğŸ“ æœ¬åœ°æ¨¡å‹ç®¡ç†

### å½“å‰å¯ç”¨æ¨¡å‹

æ ¹æ®æ‚¨çš„ç¯å¢ƒï¼Œæœ‰ä»¥ä¸‹æœ¬åœ°æ¨¡å‹ï¼š

```
models/
â”œâ”€â”€ Qwen3-4B-Thinking-2507-FP8/     # 4B å‚æ•°ï¼ŒFP8é‡åŒ–
â””â”€â”€ Qwen3-30B-A3B-Thinking-2507/    # 30B å‚æ•°ï¼Œæ ‡å‡†ç²¾åº¦
```

### æ¨¡å‹æ–‡ä»¶æ£€æŸ¥

ç¡®ä¿æ¯ä¸ªæ¨¡å‹ç›®å½•åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š
- `config.json` - æ¨¡å‹é…ç½®
- `tokenizer.json` - åˆ†è¯å™¨é…ç½®  
- `model.safetensors` æˆ– `model-*.safetensors` - æ¨¡å‹æƒé‡
- `tokenizer_config.json` - åˆ†è¯å™¨è®¾ç½®

---

## ğŸš€ åŸºæœ¬ä½¿ç”¨

### 1. æ¨¡å‹æ¨ç† (swift infer)

#### æ¨ç†å°æ¨¡å‹ (4Bï¼Œæ¨èå¼€å§‹ä½¿ç”¨)

```bash
CUDA_VISIBLE_DEVICES=0 swift infer \
    --model ./models/Qwen3-4B-Thinking-2507-FP8 \
    --stream true \
    --infer_backend pt \
    --max_new_tokens 2048 \
    --temperature 0.7
```

#### æ¨ç†å¤§æ¨¡å‹ (30Bï¼Œéœ€è¦æ›´å¤šæ˜¾å­˜)

```bash
CUDA_VISIBLE_DEVICES=0 swift infer \
    --model ./models/Qwen3-30B-A3B-Thinking-2507 \
    --stream true \
    --infer_backend pt \
    --max_new_tokens 2048 \
    --temperature 0.7 \
    --load_in_8bit true
```

### 2. æ¨¡å‹å¾®è°ƒ (swift sft)

#### å¾®è°ƒå°æ¨¡å‹

```bash
CUDA_VISIBLE_DEVICES=0 swift sft \
    --model ./models/Qwen3-4B-Thinking-2507-FP8 \
    --dataset AI-ModelScope/alpaca-gpt4-data-zh#500 \
    --train_type lora \
    --torch_dtype bfloat16 \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --learning_rate 1e-4 \
    --lora_rank 8 \
    --lora_alpha 32 \
    --target_modules all-linear \
    --gradient_accumulation_steps 16 \
    --output_dir ./output/qwen3-4b-lora \
    --max_length 2048 \
    --system 'You are a helpful assistant.'
```

#### å¾®è°ƒå¤§æ¨¡å‹ (ä½¿ç”¨é‡åŒ–)

```bash
CUDA_VISIBLE_DEVICES=0 swift sft \
    --model ./models/Qwen3-30B-A3B-Thinking-2507 \
    --dataset AI-ModelScope/alpaca-gpt4-data-zh#500 \
    --train_type lora \
    --torch_dtype bfloat16 \
    --load_in_8bit true \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --learning_rate 1e-4 \
    --lora_rank 8 \
    --lora_alpha 32 \
    --target_modules all-linear \
    --gradient_accumulation_steps 32 \
    --output_dir ./output/qwen3-30b-lora \
    --max_length 2048
```

### 3. Web UI ç•Œé¢

å¯åŠ¨å›¾å½¢åŒ–ç•Œé¢ï¼ˆæ¨èæ–°ç”¨æˆ·ä½¿ç”¨ï¼‰ï¼š

```bash
# ä¸­æ–‡ç•Œé¢
SWIFT_UI_LANG=zh swift web-ui

# è‹±æ–‡ç•Œé¢
SWIFT_UI_LANG=en swift web-ui
```

è®¿é—® `http://localhost:7860` ä½¿ç”¨ Web ç•Œé¢ã€‚

---

## ğŸ¯ é«˜çº§åŠŸèƒ½

### 1. æ¨¡å‹éƒ¨ç½² (swift deploy)

å°†æ¨¡å‹éƒ¨ç½²ä¸º API æœåŠ¡ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 swift deploy \
    --model ./models/Qwen3-4B-Thinking-2507-FP8 \
    --infer_backend vllm \
    --port 8000
```

### 2. æ¨¡å‹è¯„æµ‹ (swift eval)

è¯„æµ‹æ¨¡å‹æ€§èƒ½ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 swift eval \
    --model ./models/Qwen3-4B-Thinking-2507-FP8 \
    --infer_backend pt \
    --eval_backend OpenCompass \
    --eval_dataset ARC_c MMLU
```

### 3. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹

è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ adapters è¿›è¡Œæ¨ç†ï¼š

```bash
# æ¨ç†å¾®è°ƒåçš„æ¨¡å‹
CUDA_VISIBLE_DEVICES=0 swift infer \
    --adapters ./output/qwen3-4b-lora/vx-xxx/checkpoint-xxx \
    --stream true \
    --temperature 0.7 \
    --max_new_tokens 2048
```

### 4. åˆå¹¶ LoRA æƒé‡

```bash
# åˆå¹¶ LoRA åˆ°åŸºç¡€æ¨¡å‹
CUDA_VISIBLE_DEVICES=0 swift export \
    --adapters ./output/qwen3-4b-lora/vx-xxx/checkpoint-xxx \
    --merge_lora true \
    --output_dir ./merged_model
```

### 5. æ¨¡å‹é‡åŒ–

```bash
# AWQ é‡åŒ–
CUDA_VISIBLE_DEVICES=0 swift export \
    --model ./models/Qwen3-4B-Thinking-2507-FP8 \
    --quant_bits 4 \
    --quant_method awq \
    --dataset AI-ModelScope/alpaca-gpt4-data-zh \
    --output_dir ./qwen3-4b-awq
```

---

## ğŸ”§ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. bitsandbytes é”™è¯¯

**é—®é¢˜**: `ModuleNotFoundError: No module named 'triton.ops'`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³•1: é‡æ–°å®‰è£…ä¾èµ–
pip uninstall bitsandbytes triton
pip install bitsandbytes triton

# æ–¹æ³•2: ä½¿ç”¨ CPU æ¨¡å¼
export USE_BNB=0

# æ–¹æ³•3: é¿å…ä½¿ç”¨é‡åŒ–
# å»æ‰ --load_in_8bit å’Œ --load_in_4bit å‚æ•°
```

### 2. æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¯ç”¨é‡åŒ–
--load_in_8bit true
# æˆ–è€…
--load_in_4bit true

# å‡å°‘æ‰¹å¤„ç†å¤§å°
--per_device_train_batch_size 1

# å¢åŠ æ¢¯åº¦ç´¯ç§¯
--gradient_accumulation_steps 32

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
--gradient_checkpointing true
```

### 3. CUDA ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 4. æ¨¡å‹åŠ è½½å¤±è´¥

**æ£€æŸ¥åˆ—è¡¨**:
- [ ] æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
- [ ] æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´
- [ ] æƒé™æ˜¯å¦æ­£ç¡®
- [ ] ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç¡¬ä»¶é€‰æ‹©å»ºè®®

| æ¨¡å‹å¤§å° | æ¨èæ˜¾å­˜ | é‡åŒ–é€‰é¡¹ | æ‰¹å¤„ç†å¤§å° |
|---------|---------|---------|------------|
| 4B      | 8GB+    | å¯é€‰     | 2-4        |
| 7B      | 16GB+   | æ¨è     | 1-2        |
| 13B     | 24GB+   | å¿…éœ€     | 1          |
| 30B+    | 40GB+   | å¿…éœ€     | 1          |

### 2. è®­ç»ƒå‚æ•°è°ƒä¼˜

```bash
# å°æ¨¡å‹æ¨èé…ç½®
--lora_rank 8
--lora_alpha 32
--learning_rate 1e-4
--warmup_ratio 0.05

# å¤§æ¨¡å‹æ¨èé…ç½®
--lora_rank 16
--lora_alpha 64
--learning_rate 5e-5
--warmup_ratio 0.1
```

### 3. æ•°æ®é›†å»ºè®®

```bash
# ä½¿ç”¨å†…ç½®æ•°æ®é›†
--dataset AI-ModelScope/alpaca-gpt4-data-zh#1000

# ä½¿ç”¨å¤šä¸ªæ•°æ®é›†
--dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \
          'AI-ModelScope/alpaca-gpt4-data-en#500' \
          'swift/self-cognition#500'

# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†
--dataset /path/to/your/dataset.jsonl
```

### 4. æ€§èƒ½ä¼˜åŒ–

```bash
# å¯ç”¨ Flash Attention
--use_flash_attn true

# ä½¿ç”¨æ··åˆç²¾åº¦
--torch_dtype bfloat16

# å¤šè¿›ç¨‹æ•°æ®åŠ è½½
--dataloader_num_workers 4

# ç¼–è¯‘ä¼˜åŒ–
--torch_compile true
```

### 5. ç›‘æ§å’Œæ—¥å¿—

```bash
# å¯ç”¨ TensorBoard
--logging_dir ./logs
--report_to tensorboard

# è®¾ç½®ä¿å­˜ç­–ç•¥
--save_steps 100
--eval_steps 100
--save_total_limit 3

# è¯¦ç»†æ—¥å¿—
--logging_steps 10
```

---

## ğŸ“‹ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# å¿«é€Ÿæ¨ç†
swift infer --model ./models/Qwen3-4B-Thinking-2507-FP8

# å¿«é€Ÿå¾®è°ƒ
swift sft --model ./models/Qwen3-4B-Thinking-2507-FP8 --dataset alpaca

# å¯åŠ¨ Web UI
swift web-ui

# éƒ¨ç½²æœåŠ¡
swift deploy --model ./models/Qwen3-4B-Thinking-2507-FP8

# æ¨¡å‹è¯„æµ‹
swift eval --model ./models/Qwen3-4B-Thinking-2507-FP8

# æŸ¥çœ‹æ”¯æŒçš„æ¨¡å‹
swift list-models

# æŸ¥çœ‹æ”¯æŒçš„æ•°æ®é›†
swift list-datasets

# æŸ¥çœ‹å¸®åŠ©
swift --help
swift sft --help
swift infer --help
```

---

## ğŸ”— ç›¸å…³èµ„æº

- [MS-SWIFT GitHub](https://github.com/modelscope/ms-swift)
- [ä¸­æ–‡æ–‡æ¡£](https://swift.readthedocs.io/zh-cn/latest/)
- [è‹±æ–‡æ–‡æ¡£](https://swift.readthedocs.io/en/latest/)
- [ModelScope ç¤¾åŒº](https://modelscope.cn/)
- [é—®é¢˜åé¦ˆ](https://github.com/modelscope/ms-swift/issues)

---

**æœ€åæ›´æ–°**: 2025å¹´10æœˆ12æ—¥

**æ³¨æ„**: ä½¿ç”¨å‰è¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒæ»¡è¶³ç¡¬ä»¶å’Œè½¯ä»¶è¦æ±‚ï¼Œå¹¶æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å‚æ•°é…ç½®ã€‚